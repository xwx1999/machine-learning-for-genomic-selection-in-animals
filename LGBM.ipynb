{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5aeddecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn import DataParallel\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X_item = self.X[index]\n",
    "        y_item = self.y[index]\n",
    "        return X_item, y_item\n",
    "\n",
    "\n",
    "def SNPDataset(dataset_type, reduction=None):\n",
    "    if dataset_type == 1:\n",
    "        root_X = 'Dataset1/FileS1/genotypes.txt'\n",
    "        root_Y = 'Dataset1/FileS1/ebvs.txt'\n",
    "        X_row = 1\n",
    "        X_column = 2\n",
    "        Y_row = 1\n",
    "        Y_column = 1\n",
    "\n",
    "    elif dataset_type == 2:\n",
    "        root_X = 'Dataset2/genotype.csv'\n",
    "        root_Y = 'Dataset2/mortality_EBV.csv'\n",
    "        X_row = 1\n",
    "        X_column = 2\n",
    "        Y_row = 2\n",
    "        Y_column = 1\n",
    "\n",
    "    elif dataset_type == 4:\n",
    "        root_X = 'Dataset4/simulated.csv'\n",
    "        root_Y = 'Dataset4/simulated.csv'\n",
    "        X_row = 1\n",
    "        X_column = 1\n",
    "        Y_row = 0\n",
    "        Y_column = 0\n",
    "\n",
    "\n",
    "    X = pd.read_csv(root_X, header=None, low_memory=False)\n",
    "    Y = pd.read_csv(root_Y, header=None, low_memory=False)\n",
    "    X = X.iloc[X_row:, X_column:]\n",
    "    Y = Y.iloc[Y_row:, Y_column]\n",
    "    X = X.reset_index(drop=True)\n",
    "    Y = Y.reset_index(drop=True)\n",
    "    df = pd.concat([X, Y], axis=1)\n",
    "    df = df.sample(frac=1)\n",
    "    X = df.iloc[:, :-1]\n",
    "    Y = df.iloc[:, -1]\n",
    "    num_train = math.floor(X.shape[0]*0.8)\n",
    "\n",
    "    Xtrain = X.iloc[:num_train]\n",
    "    Xtrain = Xtrain.fillna(Xtrain.mean()).values\n",
    "    Ytrain = Y.iloc[:num_train].values\n",
    "    Xtest = X.iloc[num_train:].values\n",
    "    Ytest = Y.iloc[num_train:].values\n",
    "\n",
    "    if dataset_type == 4:\n",
    "        Ytrain = (Ytrain-Ytrain.mean())/Ytrain.std()\n",
    "        Ytest = (Ytest - Ytest.mean()) / Ytest.std()\n",
    "\n",
    "    if reduction == \"PCA\":\n",
    "        pca = PCA(n_components = Xtest.shape[0])\n",
    "        Xtrain, Xtest = pca.fit_transform(Xtrain), pca.fit_transform(Xtest)\n",
    "    elif reduction == \"ICA\":\n",
    "        ica = FastICA(n_components = Xtest.shape[0])\n",
    "        Xtrain, Xtest = ica.fit_transform(Xtrain), ica.fit_transform(Xtest)\n",
    "    elif reduction == \"TSNE\":\n",
    "        tsne = TSNE(n_components=3)\n",
    "        Xtrain, Xtest = tsne.fit_transform(Xtrain), tsne.fit_transform(Xtest)\n",
    "    # elif reduction == \"AE\":\n",
    "\n",
    "    Xtrain = Xtrain.astype(np.float32)\n",
    "    Ytrain = Ytrain.astype(np.float32)\n",
    "    Xtest = Xtest.astype(np.float32)\n",
    "    Ytest = Ytest.astype(np.float32)\n",
    "\n",
    "    return Xtrain,Ytrain,Xtest,Ytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b62f8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn import DataParallel\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def run(data_type):\n",
    "    \n",
    "\n",
    "\n",
    "    # Dataset(not for Transformer)\n",
    "    LGBM_mse = []\n",
    "    LGBM_r_sqr = []\n",
    "\n",
    "\n",
    "    for i in tqdm(range(5)):\n",
    "        Xtrain, Ytrain, Xtest, Ytest = SNPDataset(data_type)        \n",
    "        #LGBM\n",
    "        # 将数据转换为LightGBM所需的数据格式\n",
    "        train_data = lgb.Dataset(Xtrain, label=Ytrain)\n",
    "        \n",
    "        # 设置模型参数\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',  # 使用梯度提升树算法\n",
    "            'objective': 'regression',  # 回归任务\n",
    "            'metric': 'rmse',  # 使用均方根误差评估模型性能\n",
    "            'num_leaves': 31,  # 每棵树的叶子节点数目\n",
    "            'learning_rate': 0.05,  # 学习率\n",
    "            'feature_fraction': 0.9,  # 每次迭代时随机选择特征的比例\n",
    "            'bagging_fraction': 0.8,  # 每次迭代时随机选择数据的比例\n",
    "            'bagging_freq': 5,  # bagging的频率\n",
    "            'verbose': 0  # 控制训练过程中输出的信息\n",
    "        }\n",
    "        start_time = time.time()\n",
    "        # 训练模型\n",
    "        model = lgb.train(params, train_data, num_boost_round=100)\n",
    "        end_time = time.time()\n",
    "        train_time = end_time - start_time\n",
    "        start_time = time.time()\n",
    "        # 使用训练好的模型进行预测\n",
    "        Ypred = model.predict(Xtest)\n",
    "        end_time = time.time()\n",
    "        test_time = end_time - start_time\n",
    "        \n",
    "        mse_result = mse(Ytest, Ypred)\n",
    "        r_squared = r2_score(Ytest, Ypred)\n",
    "        LGBM_mse.append(mse_result)\n",
    "        LGBM_r_sqr.append(r_squared)\n",
    "        print(mse_result)\n",
    "        print(r_squared)\n",
    "        \n",
    "        test_log = []\n",
    "        test_log.append([train_time, test_time, mse_result, r_squared])\n",
    "        test_log = pd.DataFrame(test_log, columns=['train_time', 'test_time', 'MSE score', 'R-squared'])\n",
    "        os.makedirs(\"Dataset\" + str(data_type) + \"/LGBM\", exist_ok=True)\n",
    "        test_log.to_csv(\"Dataset\" + str(data_type) + \"/LGBM/test_log_\" + str(i) + \".csv\", index=False)\n",
    "        \n",
    "\n",
    "    LGBM_mse_mean, LGBM_mse_std = np.mean(LGBM_mse), np.std(LGBM_mse)\n",
    "    LGBM_r_mean, LGBM_r_std = np.mean(LGBM_r_sqr), np.std(LGBM_r_sqr)\n",
    "    print(\"LGBM:\")\n",
    "    print(LGBM_mse_mean, LGBM_mse_std)\n",
    "    print(LGBM_r_mean, LGBM_r_std)\n",
    "    print('-' * 100)\n",
    "\n",
    "\n",
    "\n",
    "    log = {\n",
    "           'LGBM': [LGBM_mse_mean, LGBM_mse_std, LGBM_r_mean, LGBM_r_std],\n",
    "           }\n",
    "    log = pd.DataFrame(log)\n",
    "    log.to_csv(\"Dataset\" + str(data_type) + \"/log.csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3eb6e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▊                                                                   | 1/5 [00:12<00:49, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8886254572366729\n",
      "0.11137454834259164\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:23<00:35, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8694224832989218\n",
      "0.13057751945811946\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:35<00:23, 11.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8615537747482143\n",
      "0.13844622543965668\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:47<00:11, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8614692561557966\n",
      "0.1385307400630693\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:58<00:00, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8564238399412201\n",
      "0.143576163451263\n",
      "LGBM:\n",
      "0.8674989622761651 0.011352441744539862\n",
      "0.13250103935094001 0.011352439854487483\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be8a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
